{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabalho Prático de Introdução a Ciência dos Dados\n",
    "\n",
    "\n",
    "### Integrantes:\n",
    "- Bruno Henrique Evangelista Pereira\n",
    "- Francisco Teixeira Rocha Aragão\n",
    "- Lorenzo Carneiro Magalhaes\n",
    "- Tomas Lacerda Muniz\n",
    "- Victor de Almeida Nunes Murta\n",
    "\n",
    "##### Para mais informações, checar [README.MD](README.md)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Como o moodle não suporta arquivos com mais de 20 mb, não foi possível fazer o upload com os arquivos *.csv*, devido a isso, é necessário baixá-los**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from deep_translator import GoogleTranslator\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos importar um dataset de tweets sobre o chatgpt, que pode ser encontrado em: [chatGPT-1000-daily-tweets](https://www.kaggle.com/datasets/edomingo/chatgpt-1000-daily-tweets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/chatgpt_daily_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir das primeiras linhas do dataframe é possível perceber que ele possui uma grande variedade de informações sobre cada tweet, mas a maioria não será utilizada em nossa análise. Então, vamos começar filtrando as informações relevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atributos_drop = ['tweet_extracted', 'tweet_id', 'user_description', 'user_created', 'user_followers_count', 'user_following_count', \n",
    "                     'source', 'user_tweet_count', 'user_verified', 'user_id', 'user_name', 'user_username']\n",
    "df = df.drop(columns=atributos_drop)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que o dataframe já está limpo, é necessário filtrar os tweets relevantes. Para isso, vamos retirar todos os tweets que não possuem curtidas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Tamanho original:', len(df))\n",
    "df_relevante = df.query('like_count > 0')\n",
    "print('Tamanho após filtragem:', len(df_relevante))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note como a quantidade de tweets diminuiu em quase 10 vezes. Isso se deve ao fato de que boa parte dos tweets são criados por bots, que pretendemos ignorar\n",
    "\n",
    "Uma informação que é de grande utilidade é o intervalo de datas que o dataset abrange. Vamos conferir quais são as datas do primeiro e do último tweet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_relevante.sort_values('tweet_created')\n",
    "print(df_new.iloc[0]['tweet_created'])\n",
    "print(df_new.iloc[-1]['tweet_created'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Também é interessante tentar entender como se comportam as curtidas no nosso conjunto de tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_relevante_copy = df_relevante.copy()\n",
    "df_relevante_copy['like_count_log'] = np.log(df_relevante_copy['like_count'])\n",
    "\n",
    "df_relevante_copy['like_count_log'].hist(bins=9, alpha=1)\n",
    "plt.title('Distribuição')\n",
    "plt.xlabel('Ordem de magnitude dos likes')\n",
    "plt.ylabel('Frequência')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vamos entender qual é a distribuição das linguas dos tweets no dataframe filtrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ordena as quantidades e tira as linguas com menos de 50 tweets\n",
    "df_linguas = df_relevante.groupby('lang').count()[['text']].reset_index().rename(columns={'text': 'quantidade'})\n",
    "df_linguas = df_linguas.sort_values('quantidade', ascending = True)\n",
    "df_linguas = df_linguas.query('quantidade >= 50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.barh(df_linguas['lang'], df_linguas['quantidade'])\n",
    "plt.xlabel('Idioma')\n",
    "plt.ylabel('Quantidade')\n",
    "plt.title('Quantidade por idioma')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No nosso trabalho pretendemos utilizar um algoritmo para medir a emoção associada a cada tweet sobre o chatGPT. Entretanto, o algoritmo utilizado não é capaz de fazer essa análise para linguas diferentes do inglês, então é necessário traduzir todos os tweets para o inglês antes de fazer a análise\n",
    "\n",
    "Vamos utilizar apenas os 100 primeiros tweets já que a tradução utiliza uma api do google, então traduzir todas as linhas leva muito tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traduzir(tweet):\n",
    "    return GoogleTranslator(source='auto', target='en').translate(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_100 = df_relevante[0:100].copy()\n",
    "df_100['traduzido'] = df_100['text'].apply(traduzir)\n",
    "df_100.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que temos uma coluna traduzida, podemos criar colunas para as análises de sentimento (negativo, positivo e neutro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.classification.vaderFunctions import classify\n",
    "\n",
    "# 1 for positive\n",
    "# 0 for neutral\n",
    "# -1 for negative\n",
    "\n",
    "df_100['sentimental_label'] = df_100['traduzido'].apply(classify)\n",
    "df_100.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esses sentimentos serão explorados na versão final do projeto. O foco é entender as variações dos sentimentos em relação ao chatGPT à medida que notícias relacionadas à tecnologia eram distribuidas.\n",
    "\n",
    "Para mais uma amostra da análise de sentimento, realizamos um teste com uma amostra gerada e classificada manualmente para verificarmos a acurácia do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.classification.sampleVader import vader_sample_test\n",
    "\n",
    "vader_sample_test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tpICD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
