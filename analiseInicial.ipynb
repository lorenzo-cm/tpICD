{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from deep_translator import GoogleTranslator\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vamos importar um dataset de tweets sobre o chatgpt, que pode ser encontrado em: https://www.kaggle.com/datasets/edomingo/chatgpt-1000-daily-tweets**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('chatgpt_daily_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A partir das primeiras linhas do dataframe é possível perceber que ele possui uma grande variedade de informações sobre cada tweet, mas a maioria não será utilizada em nossa análise. Então, vamos começar filtrando as informações relevantes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atributos_drop = ['tweet_extracted', 'tweet_id', 'user_description', 'user_created', 'user_followers_count', 'user_following_count', \n",
    "                     'source', 'user_tweet_count', 'user_verified', 'user_id', 'user_name', 'user_username']\n",
    "df = df.drop(columns=atributos_drop)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Agora que o dataframe já está limpo, é necessário filtrar os tweets relevantes. Para isso, vamos retirar todos os tweets que não possuem curtidas**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df))\n",
    "df_relevante = df.query('like_count > 0')\n",
    "print(len(df_relevante))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note como a quantidade de tweets diminuiu em quase 10 vezes. Isso se deve ao fato de que boa parte dos tweets são criados por bots, que pretendemos ignorar**\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Uma informação que é de grande utilidade é o intervalo de datas que o dataset abrange. Vamos conferir quais são as datas do primeiro e do último tweet:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.iloc[0]['tweet_created'])\n",
    "print(df.iloc[-1]['tweet_created'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Também é interessante tentar entender como se comportam as curtidas no nosso conjunto de tweets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_relevante['like_count_log'] = np.log(df_relevante['like_count'])\n",
    "\n",
    "df_relevante['like_count_log'].hist(bins=9, alpha=1)\n",
    "plt.title('Distribuição')\n",
    "plt.xlabel('Ordem de magnitude dos likes')\n",
    "plt.ylabel('Frequência')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Agora, vamos entender qual é a distribuição das linguas dos tweets no dataframe filtrado**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_linguas = df_relevante.groupby('lang').count()[['text']].reset_index().rename(columns={'text': 'quantidade'})\n",
    "df_linguas = df_linguas.sort_values('quantidade', ascending = False)\n",
    "df_linguas = df_linguas.query('quantidade >= 50')\n",
    "#ordena as quantidades e tira as linguas com menos de 50 tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(df_linguas['lang'], df_linguas['quantidade'])\n",
    "plt.xlabel('Lingua')\n",
    "plt.ylabel('quantiadade')\n",
    "plt.title('Quantidade por lingua')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**No nosso trabalho pretendemos utilizar um algoritmo para medir a emoção associada a cada tweet sobre o chatGPT. Entretanto, o algoritmo utilizado não é capaz de fazer essa análise para linguas diferentes do inglês, então é necessário traduzi todos os tweets para o inglês antes de fazer a análise**\n",
    "**Vamos utilizar apenas os 100 primeiros tweets já que a tradução utuliza uma api do google, então traduzir todas as linhas leva muito tempo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traduzir(tweet):\n",
    "    return GoogleTranslator(source='auto', target='en').translate(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_100 = df_relevante.head(100)\n",
    "df_100['traduzido'] = df_100['text'].apply(traduzir)\n",
    "df_100.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Agora que temos uma coluna traduzida, podemos criar colunas para as análises de sentimento (negativo, positivo e neutro)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "def analisar(tweet, tipo):\n",
    "    result = analyzer.polarity_scores(tweet)\n",
    "    return result[tipo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_100['neg'] = df_100['traduzido'].apply(lambda x: analisar(x, 'neg'))\n",
    "df_100['pos'] = df_100['traduzido'].apply(lambda x: analisar(x, 'pos'))\n",
    "df_100['neu'] = df_100['traduzido'].apply(lambda x: analisar(x, 'neu'))\n",
    "df_100.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Esses sentimentos serão explorados na versão final do projeto. O foco é entender as variações dos sentimentos em relação ao chatGPT à medida que notícias relacionadas à tecnologia eram distribuidas**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tpICD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
